{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-NET Implementation\n",
    "\n",
    "U-NET Implementation based in it's paper using Pytorch.\n",
    "\n",
    "## References:\n",
    "\n",
    "Original paper at [arxiv](https://arxiv.org/abs/1505.04597).\n",
    "\n",
    "Great [video explaining the architecture](https://www.youtube.com/watch?v=NhdzGfB1q74).\n",
    "\n",
    "Implementation [coded along with this video](https://www.youtube.com/watch?v=IHq1t7NxS8k).\n",
    "\n",
    "## Architecture:\n",
    "\n",
    "UNET (name given because of the shape of the architecure) uses a Encoder-Decoder architecture. The encoder is responsible for extracting features from the image by downsizing it using CNN's (followed by ReLU) and max pooling (while the net downsizes it, the channels double for each step). The decoder is responsible for upsampling the image (using Transposed Convolution). While upsampling, the Net halves the channels for each step.\n",
    "\n",
    "Each connection (gray arrows) concatenates the equivalent images in upscaling and downscaling. This step is in important, for instance, for image segmentation, so the Net can learn how pixel-perfectly delimit objects in an image given it's mask.\n",
    "\n",
    "\n",
    "![Architecture for U-NET](architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "- The original paper did not include Batch Normalization in it's architecture, but using it here stabilizes learning, allows higher learning rates and faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, \n",
    "                      out_channels, \n",
    "                      kernel_size=3, \n",
    "                      stride=1,\n",
    "                      padding=1,\n",
    "                      bias=False), # bias is cancelled by BatchNorm\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, \n",
    "                      out_channels, \n",
    "                      kernel_size=3, \n",
    "                      stride=1,\n",
    "                      padding=1,\n",
    "                      bias=False), # bias is cancelled by BatchNorm\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(UNET, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Going downwards\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Going Upwards\n",
    "        for feature in reversed(features):\n",
    "            # Upsampling\n",
    "            self.ups.append(nn.ConvTranspose2d(feature*2, \n",
    "                                               feature, \n",
    "                                               kernel_size=2,\n",
    "                                               stride=2))\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], 2*features[-1]) # dowmonst Double Convolution\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1) # conv 1x1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        # Encoding\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        # At this point, skip_connections has copies of the encoding steps\n",
    "        # The Decoding part needs to concatenate these copies onto the\n",
    "        # upsampling steps\n",
    "\n",
    "        # Decoding\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "\n",
    "            # Originally, the Net accepts only dimensions\n",
    "            # that are multiple of 16 (4 max pools -> 2^4)\n",
    "            # To solve this, \n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size=skip_connection.shape[2:]) # [2:] skips batch size & number of channels\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "        \n",
    "        return self.final_conv(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
